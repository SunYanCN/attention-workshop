{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, SeparableConv2D\n",
    "from keras.layers import Bidirectional, RepeatVector, TimeDistributed, Permute, Embedding\n",
    "from keras.layers import concatenate, add, Lambda, multiply\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.applications import imagenet_utils, Xception\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import TrainingMonitor\n",
    "from helpers import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_file = open('../input/dataset/X.pickle', 'rb')\n",
    "x = pickle.load(X_file)\n",
    "X_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_file = open('../input/dataset/Y.pickle', 'rb')\n",
    "y = pickle.load(Y_file)\n",
    "Y_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_input = np.zeros([1000, 10])\n",
    "y_input[:, 1:] = y[:,:-1]\n",
    "y_input[:, 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.,   2.,  10.,  10.,   9.,   0.,   1.,   6.,   0.,   1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yoh_file = open('../input/dataset/Yoh.pickle', 'rb')\n",
    "yoh = pickle.load(Yoh_file)\n",
    "Yoh_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_split, val_split = 0.7, 0.15\n",
    "\n",
    "train_len = int(train_split * x.shape[0])\n",
    "train_val_len = int((train_split + val_split) * x.shape[0])\n",
    "\n",
    "x_train = x[:train_len]\n",
    "x_val = x[train_len:train_val_len]\n",
    "x_test = x[train_val_len:]\n",
    "\n",
    "y_input_train = y_input[:train_len]\n",
    "y_input_val = y_input[train_len:train_val_len]\n",
    "y_input_test = y_input[train_val_len:]\n",
    "\n",
    "yoh_train = yoh[:train_len]\n",
    "yoh_val = yoh[train_len:train_val_len]\n",
    "yoh_test = yoh[train_val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoh_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_LENGTH = 30\n",
    "OUTPUT_LENGTH = 10\n",
    "input_dict_size = 37\n",
    "output_dict_size = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
    "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder Tensor(\"bidirectional_1/concat:0\", shape=(?, 30, 128), dtype=float32)\n",
      "encoder_last Tensor(\"strided_slice:0\", shape=(?, 128), dtype=float32)\n",
      "decoder Tensor(\"lstm_2/transpose_2:0\", shape=(?, 10, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoder = Embedding(input_dict_size, 64, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
    "encoder = Bidirectional(LSTM(64, return_sequences=True, unroll=True))(encoder)\n",
    "encoder_last = encoder[:,-1,:]\n",
    "\n",
    "print('encoder', encoder)\n",
    "print('encoder_last', encoder_last)\n",
    "\n",
    "decoder = Embedding(output_dict_size, 64, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
    "decoder = LSTM(128, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n",
    "\n",
    "print('decoder', decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, dot, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention Tensor(\"attention/truediv:0\", shape=(?, 10, 30), dtype=float32)\n",
      "context Tensor(\"dot_2/MatMul:0\", shape=(?, 10, 128), dtype=float32)\n",
      "decoder_combined_context Tensor(\"concatenate_1/concat:0\", shape=(?, 10, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attention = dot([decoder, encoder], axes=[2, 2])\n",
    "attention = Activation('softmax', name='attention')(attention)\n",
    "print('attention', attention)\n",
    "\n",
    "context = dot([attention, encoder], axes=[2,1])\n",
    "print('context', context)\n",
    "\n",
    "decoder_combined_context = concatenate([context, decoder])\n",
    "print('decoder_combined_context', decoder_combined_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_combined_context)\n",
    "output = TimeDistributed(Dense(11, activation=\"softmax\"))(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 10, 64)       704         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 64)       2368        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 10, 128)      98816       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 128)      66048       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 10, 30)       0           lstm_2[0][0]                     \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, 10, 30)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 10, 128)      0           attention[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 256)      0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 10, 64)       16448       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 10, 11)       715         time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 185,099\n",
      "Trainable params: 185,099\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 150 samples\n",
      "Epoch 1/50\n",
      "700/700 [==============================] - 14s 20ms/step - loss: 0.2897 - acc: 0.9084 - val_loss: 0.2750 - val_acc: 0.9091\n",
      "Epoch 2/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.2623 - acc: 0.9090 - val_loss: 0.2420 - val_acc: 0.9168\n",
      "Epoch 3/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.2298 - acc: 0.9192 - val_loss: 0.2132 - val_acc: 0.9273\n",
      "Epoch 4/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.2009 - acc: 0.9343 - val_loss: 0.1887 - val_acc: 0.9388\n",
      "Epoch 5/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.1720 - acc: 0.9420 - val_loss: 0.1579 - val_acc: 0.9448\n",
      "Epoch 6/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.1487 - acc: 0.9467 - val_loss: 0.1421 - val_acc: 0.9476\n",
      "Epoch 7/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.1394 - acc: 0.9486 - val_loss: 0.1354 - val_acc: 0.9486\n",
      "Epoch 8/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.1307 - acc: 0.9527 - val_loss: 0.1279 - val_acc: 0.9550\n",
      "Epoch 9/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.1243 - acc: 0.9552 - val_loss: 0.1192 - val_acc: 0.9570\n",
      "Epoch 10/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.1175 - acc: 0.9573 - val_loss: 0.1118 - val_acc: 0.9601\n",
      "Epoch 11/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.1088 - acc: 0.9600 - val_loss: 0.1037 - val_acc: 0.9619\n",
      "Epoch 12/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.1005 - acc: 0.9621 - val_loss: 0.0976 - val_acc: 0.9623\n",
      "Epoch 13/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0936 - acc: 0.9641 - val_loss: 0.0896 - val_acc: 0.9642\n",
      "Epoch 14/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0849 - acc: 0.9660 - val_loss: 0.0822 - val_acc: 0.9675\n",
      "Epoch 15/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0763 - acc: 0.9691 - val_loss: 0.0755 - val_acc: 0.9702\n",
      "Epoch 16/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0679 - acc: 0.9725 - val_loss: 0.0681 - val_acc: 0.9730\n",
      "Epoch 17/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0596 - acc: 0.9769 - val_loss: 0.0605 - val_acc: 0.9783\n",
      "Epoch 18/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0508 - acc: 0.9817 - val_loss: 0.0509 - val_acc: 0.9819\n",
      "Epoch 19/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0406 - acc: 0.9876 - val_loss: 0.0422 - val_acc: 0.9860\n",
      "Epoch 20/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0325 - acc: 0.9901 - val_loss: 0.0328 - val_acc: 0.9904\n",
      "Epoch 21/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0238 - acc: 0.9932 - val_loss: 0.0247 - val_acc: 0.9927\n",
      "Epoch 22/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0181 - acc: 0.9948 - val_loss: 0.0193 - val_acc: 0.9943\n",
      "Epoch 23/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0145 - acc: 0.9956 - val_loss: 0.0161 - val_acc: 0.9956\n",
      "Epoch 24/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0141 - val_acc: 0.9958\n",
      "Epoch 25/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0124 - val_acc: 0.9967\n",
      "Epoch 26/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0109 - val_acc: 0.9966\n",
      "Epoch 27/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0098 - val_acc: 0.9976\n",
      "Epoch 28/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0044 - acc: 0.9993 - val_loss: 0.0097 - val_acc: 0.9977\n",
      "Epoch 29/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0042 - acc: 0.9994 - val_loss: 0.0094 - val_acc: 0.9975\n",
      "Epoch 30/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.0091 - val_acc: 0.9983\n",
      "Epoch 31/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0026 - acc: 0.9998 - val_loss: 0.0091 - val_acc: 0.9982\n",
      "Epoch 32/50\n",
      "700/700 [==============================] - 2s 4ms/step - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0087 - val_acc: 0.9981\n",
      "Epoch 33/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0023 - acc: 0.9997 - val_loss: 0.0077 - val_acc: 0.9978\n",
      "Epoch 34/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0021 - acc: 0.9997 - val_loss: 0.0067 - val_acc: 0.9984\n",
      "Epoch 35/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0071 - val_acc: 0.9983\n",
      "Epoch 36/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0015 - acc: 0.9999 - val_loss: 0.0079 - val_acc: 0.9981\n",
      "Epoch 37/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0078 - val_acc: 0.9983\n",
      "Epoch 38/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0084 - val_acc: 0.9980\n",
      "Epoch 39/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0088 - val_acc: 0.9982\n",
      "Epoch 40/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0081 - val_acc: 0.9983\n",
      "Epoch 41/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0086 - val_acc: 0.9982\n",
      "Epoch 42/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0068 - val_acc: 0.9982\n",
      "Epoch 43/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0060 - val_acc: 0.9982\n",
      "Epoch 44/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0074 - val_acc: 0.9978\n",
      "Epoch 45/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0069 - val_acc: 0.9981\n",
      "Epoch 46/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 9.7908e-04 - acc: 0.9998 - val_loss: 0.0071 - val_acc: 0.9982\n",
      "Epoch 47/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 7.0952e-04 - acc: 0.9999 - val_loss: 0.0080 - val_acc: 0.9983\n",
      "Epoch 48/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 7.1856e-04 - acc: 0.9999 - val_loss: 0.0075 - val_acc: 0.9984\n",
      "Epoch 49/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 5.8292e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9982\n",
      "Epoch 50/50\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 8.2428e-04 - acc: 0.9998 - val_loss: 0.0065 - val_acc: 0.9983\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[x_train, y_input_train], y=[yoh_train],\n",
    "            validation_data=([x_val, y_input_val], [yoh_val]),\n",
    "            verbose=1,\n",
    "            batch_size=32,\n",
    "            epochs=50,\n",
    "            shuffle=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 100.00%; Val: 99.84%; Test: 99.88%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate([x_test, y_input_test], yoh_test, verbose=0)\n",
    "print(\"Train: %.2f%%; Val: %.2f%%; Test: %.2f%%\" % \n",
    "      (np.max(history.history['acc'])*100, np.max(history.history['val_acc'])*100, scores[1]*100)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attention_layer = model.get_layer(\"attention\")\n",
    "attention_model = Model(inputs=model.inputs, outputs=model.outputs + [attention_layer.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "human_vocab_file = open('../input/dataset/human_vocab.pickle', 'rb')\n",
    "human_vocab = pickle.load(human_vocab_file)\n",
    "human_vocab_file.close()\n",
    "\n",
    "machine_vocab_file = open('../input/dataset/machine_vocab.pickle', 'rb')\n",
    "machine_vocab = pickle.load(machine_vocab_file)\n",
    "machine_vocab_file.close()\n",
    "\n",
    "input_encoding = human_vocab\n",
    "output_encoding = machine_vocab\n",
    "input_decoding = {v: k for k, v in input_encoding.items()}\n",
    "output_decoding = {v: k for k, v in output_encoding.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_input = x[0:1]\n",
    "decoder_input = y_input[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.,   2.,  10.,  10.,   9.,   0.,   1.,   6.,   0.,   1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_output= np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    output, attention = attention_model.predict([encoder_input, decoder_input])\n",
    "    decoder_output[:,i] = output.argmax(axis=2)[:,i]\n",
    "    attention_density = attention[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,  10.,  10.,   9.,   0.,   0.,   6.,   0.,   0.,  10.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 may 1998                    '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ''\n",
    "for key, value in enumerate(encoder_input[0]):\n",
    "    if value != 36:\n",
    "        text += str(input_decoding[value])\n",
    "    else:\n",
    "        text += ' '\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1998--5--9'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = ''\n",
    "for key, value in enumerate(decoder_output[0]):\n",
    "    date += str(output_decoding[value])\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2182edd4128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAFpCAYAAAA7oFbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMkk5AACMTFIOAAAj+/9xzCMoEho9QQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2182ed489b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "ax = seaborn.heatmap(attention_density[:len(date), : len(text)],\n",
    "        xticklabels=[w for w in text],\n",
    "        yticklabels=[w for w in date])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boringtao\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py:2361: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'strided_slice:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'strided_slice:0' shape=(?, 64) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"../output/saved/date_model_attention_99.81.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"../output/saved/date_weight_attention_99.81.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
