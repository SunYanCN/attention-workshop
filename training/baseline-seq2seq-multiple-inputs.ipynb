{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.applications import imagenet_utils, Xception\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import TrainingMonitor\n",
    "from helpers import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xoh_file = open('../input/dataset/Xoh.pickle', 'rb')\n",
    "x = pickle.load(Xoh_file)\n",
    "Xoh_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yoh_file = open('../input/dataset/Yoh.pickle', 'rb')\n",
    "y = pickle.load(Yoh_file)\n",
    "Yoh_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pad_sequences(y, maxlen=11, padding=\"post\", value=[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 37)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_input = np.zeros([1000, 10, 11])\n",
    "y_input[:, 1:] = y[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_split, val_split = 0.7, 0.15\n",
    "\n",
    "train_len = int(train_split * x.shape[0])\n",
    "train_val_len = int((train_split + val_split) * x.shape[0])\n",
    "\n",
    "x_train = x[:train_len]\n",
    "x_val = x[train_len:train_val_len]\n",
    "x_test = x[train_val_len:]\n",
    "\n",
    "y_input_train = y_input[:train_len]\n",
    "y_input_val = y_input[train_len:train_val_len]\n",
    "y_input_test = y_input[train_val_len:]\n",
    "\n",
    "y_train = y[:train_len]\n",
    "y_val = y[train_len:train_val_len]\n",
    "y_test = y[train_val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 30, 37)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INPUT_LENGTH = TIME_STEPS = x_train.shape[1] \n",
    "INPUT_DIM = x_train.shape[2]\n",
    "OUTPUT_LENGTH = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
    "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention(inputs):\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    a_probs = Permute((2, 1))(a)\n",
    "    output_attention_mul = multiply([inputs, a_probs])\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 128)          84992       input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_7 (RepeatVector)  (None, 10, 128)      0           lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 10, 11)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                  (None, 10, 64)       49408       repeat_vector_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_20 (LSTM)                  (None, 10, 64)       19456       input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 10, 128)      0           lstm_19[0][0]                    \n",
      "                                                                 lstm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 10, 11)       1419        concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 155,275\n",
      "Trainable params: 155,275\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers \n",
    "from keras import Input \n",
    "from keras.models import Model \n",
    "\n",
    "left_input = Input(shape=(30, 37))\n",
    "left_output = LSTM(128, return_sequences=False)(left_input)\n",
    "left_output = RepeatVector(10)(left_output)\n",
    "left_output = LSTM(64, return_sequences=True)(left_output)\n",
    "\n",
    "right_input = Input(shape=(10, 11)) \n",
    "right_output = LSTM(64, return_sequences=True)(right_input)\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1) \n",
    "\n",
    "output = TimeDistributed(Dense(11, activation=\"softmax\"))(merged) \n",
    "model = Model([left_input, right_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2464\n"
     ]
    }
   ],
   "source": [
    "output_path = \"../output/\"\n",
    "\n",
    "print(os.getpid())\n",
    "filepath=output_path + \"progress/seq2seq-mulitiheads-weights-best.hdf5\"\n",
    "MC = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "figPath = os.path.sep.join([output_path, \"monitor/{}.png\".format(os.getpid())])\n",
    "jsonPath = os.path.sep.join([output_path, \"monitor/{}.json\".format(os.getpid())])\n",
    "TM = TrainingMonitor(figPath, jsonPath=jsonPath, startAt=0)\n",
    "\n",
    "RLR = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [MC, TM, RLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 2.2363 - acc: 0.2320 - val_loss: 2.1314 - val_acc: 0.3000\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 2.0864 - acc: 0.2943 - val_loss: 2.0341 - val_acc: 0.3347\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 1.9675 - acc: 0.3567 - val_loss: 1.8855 - val_acc: 0.3600\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 1.8266 - acc: 0.4074 - val_loss: 1.7467 - val_acc: 0.4187\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.6263 - acc: 0.4740 - val_loss: 1.4342 - val_acc: 0.4720\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.3627 - acc: 0.4939 - val_loss: 1.3007 - val_acc: 0.4960\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 1.2498 - acc: 0.5341 - val_loss: 1.2125 - val_acc: 0.5473\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1911 - acc: 0.5543 - val_loss: 1.1779 - val_acc: 0.5520\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1600 - acc: 0.5547 - val_loss: 1.1422 - val_acc: 0.5500\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1307 - acc: 0.5583 - val_loss: 1.1219 - val_acc: 0.5480\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1111 - acc: 0.5569 - val_loss: 1.1015 - val_acc: 0.5507\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 1.0941 - acc: 0.5579 - val_loss: 1.0858 - val_acc: 0.5493\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 1.0790 - acc: 0.5630 - val_loss: 1.0797 - val_acc: 0.5527\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.0715 - acc: 0.5581 - val_loss: 1.0689 - val_acc: 0.5413\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.0561 - acc: 0.5574 - val_loss: 1.0610 - val_acc: 0.5467\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 1.0488 - acc: 0.5574 - val_loss: 1.0474 - val_acc: 0.5580\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 1.0395 - acc: 0.5586 - val_loss: 1.0455 - val_acc: 0.5467\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.0350 - acc: 0.5597 - val_loss: 1.0456 - val_acc: 0.5453\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 1.0283 - acc: 0.5577 - val_loss: 1.0304 - val_acc: 0.5633\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.0220 - acc: 0.5627 - val_loss: 1.0202 - val_acc: 0.5527\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 1.0176 - acc: 0.5551 - val_loss: 1.0272 - val_acc: 0.5520\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.0138 - acc: 0.5616 - val_loss: 1.0199 - val_acc: 0.5473\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.0114 - acc: 0.5636 - val_loss: 1.0257 - val_acc: 0.5493\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.0110 - acc: 0.5600 - val_loss: 1.0214 - val_acc: 0.5540\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.0061 - acc: 0.5654 - val_loss: 1.0146 - val_acc: 0.5467\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.0018 - acc: 0.5620 - val_loss: 1.0102 - val_acc: 0.5367\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.0018 - acc: 0.5633 - val_loss: 1.0134 - val_acc: 0.5480\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.0034 - acc: 0.5613 - val_loss: 1.0119 - val_acc: 0.5513\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9978 - acc: 0.5661 - val_loss: 1.0085 - val_acc: 0.5447\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.9961 - acc: 0.5651 - val_loss: 1.0080 - val_acc: 0.5520\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9958 - acc: 0.5673 - val_loss: 1.0094 - val_acc: 0.5527\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9971 - acc: 0.5654 - val_loss: 1.0136 - val_acc: 0.5487\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9923 - acc: 0.5720 - val_loss: 1.0012 - val_acc: 0.5520\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9918 - acc: 0.5689 - val_loss: 1.0094 - val_acc: 0.5413\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9935 - acc: 0.5656 - val_loss: 1.0086 - val_acc: 0.5527\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9949 - acc: 0.5619 - val_loss: 0.9968 - val_acc: 0.5533\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.9933 - acc: 0.5636 - val_loss: 1.0114 - val_acc: 0.5513\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9921 - acc: 0.5646 - val_loss: 0.9989 - val_acc: 0.5567\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.9879 - acc: 0.5720 - val_loss: 1.0017 - val_acc: 0.5520\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.9874 - acc: 0.5667 - val_loss: 1.0032 - val_acc: 0.5433\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9865 - acc: 0.5683 - val_loss: 0.9988 - val_acc: 0.5507\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.9860 - acc: 0.5713 - val_loss: 1.0052 - val_acc: 0.5433\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9815 - acc: 0.5719 - val_loss: 0.9955 - val_acc: 0.5580\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9797 - acc: 0.5730 - val_loss: 0.9974 - val_acc: 0.5487\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9789 - acc: 0.5771 - val_loss: 0.9963 - val_acc: 0.5533\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9786 - acc: 0.5764 - val_loss: 0.9965 - val_acc: 0.5573\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9779 - acc: 0.5756 - val_loss: 0.9955 - val_acc: 0.5573\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9763 - acc: 0.5793 - val_loss: 0.9943 - val_acc: 0.5567\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.9711 - acc: 0.5853 - val_loss: 0.9885 - val_acc: 0.5660\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9640 - acc: 0.5851 - val_loss: 0.9830 - val_acc: 0.5667\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9577 - acc: 0.5897 - val_loss: 0.9830 - val_acc: 0.5667\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9615 - acc: 0.5896 - val_loss: 0.9730 - val_acc: 0.5680\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9443 - acc: 0.5987 - val_loss: 0.9677 - val_acc: 0.5787\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.9378 - acc: 0.6081 - val_loss: 0.9656 - val_acc: 0.5860\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9292 - acc: 0.6146 - val_loss: 0.9538 - val_acc: 0.5813\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.9223 - acc: 0.6187 - val_loss: 0.9479 - val_acc: 0.5913\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.9158 - acc: 0.6290 - val_loss: 0.9397 - val_acc: 0.5900\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.9075 - acc: 0.6300 - val_loss: 0.9275 - val_acc: 0.5960\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.8970 - acc: 0.6389 - val_loss: 0.9217 - val_acc: 0.6040\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.8928 - acc: 0.6379 - val_loss: 0.9170 - val_acc: 0.6140\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.8835 - acc: 0.6471 - val_loss: 0.9117 - val_acc: 0.6113\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.8768 - acc: 0.6507 - val_loss: 0.8978 - val_acc: 0.6260\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.8670 - acc: 0.6560 - val_loss: 0.8955 - val_acc: 0.6293\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.8651 - acc: 0.6570 - val_loss: 0.8909 - val_acc: 0.6367\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.8564 - acc: 0.6699 - val_loss: 0.8867 - val_acc: 0.6413\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.8518 - acc: 0.6703 - val_loss: 0.8865 - val_acc: 0.6467\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.8478 - acc: 0.6766 - val_loss: 0.8807 - val_acc: 0.6367\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.8429 - acc: 0.6759 - val_loss: 0.8670 - val_acc: 0.6500\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.8354 - acc: 0.6813 - val_loss: 0.8703 - val_acc: 0.6580\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.8305 - acc: 0.6831 - val_loss: 0.8712 - val_acc: 0.6507\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.8280 - acc: 0.6893 - val_loss: 0.8579 - val_acc: 0.6640\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.8221 - acc: 0.6900 - val_loss: 0.8551 - val_acc: 0.6580\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.8105 - acc: 0.6944 - val_loss: 0.8498 - val_acc: 0.6580\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.8090 - acc: 0.6957 - val_loss: 0.8449 - val_acc: 0.6633\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.7991 - acc: 0.7041 - val_loss: 0.8377 - val_acc: 0.6680\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.7949 - acc: 0.7014 - val_loss: 0.8356 - val_acc: 0.6727\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.7920 - acc: 0.7059 - val_loss: 0.8305 - val_acc: 0.6687\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.7844 - acc: 0.7117 - val_loss: 0.8249 - val_acc: 0.6733\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.7746 - acc: 0.7151 - val_loss: 0.8136 - val_acc: 0.6793\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.7677 - acc: 0.7174 - val_loss: 0.8113 - val_acc: 0.6833\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.7606 - acc: 0.7229 - val_loss: 0.8019 - val_acc: 0.6813\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.7581 - acc: 0.7206 - val_loss: 0.7933 - val_acc: 0.6900\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.7440 - acc: 0.7334 - val_loss: 0.7955 - val_acc: 0.6967\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.7401 - acc: 0.7354 - val_loss: 0.7817 - val_acc: 0.6960\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.7342 - acc: 0.7383 - val_loss: 0.7704 - val_acc: 0.7047\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.7228 - acc: 0.7446 - val_loss: 0.7652 - val_acc: 0.7127\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.7155 - acc: 0.7493 - val_loss: 0.7674 - val_acc: 0.7073\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.7114 - acc: 0.7474 - val_loss: 0.7529 - val_acc: 0.7200\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.7024 - acc: 0.7516 - val_loss: 0.7468 - val_acc: 0.7160\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.6940 - acc: 0.7551 - val_loss: 0.7385 - val_acc: 0.7193\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6898 - acc: 0.7571 - val_loss: 0.7374 - val_acc: 0.7220\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6848 - acc: 0.7550 - val_loss: 0.7381 - val_acc: 0.7220\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.6748 - acc: 0.7657 - val_loss: 0.7305 - val_acc: 0.7200\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6726 - acc: 0.7659 - val_loss: 0.7255 - val_acc: 0.7287\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6603 - acc: 0.7719 - val_loss: 0.7182 - val_acc: 0.7340\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.6554 - acc: 0.7716 - val_loss: 0.7120 - val_acc: 0.7387\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6498 - acc: 0.7749 - val_loss: 0.7062 - val_acc: 0.7393\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6374 - acc: 0.7794 - val_loss: 0.6959 - val_acc: 0.7440\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6343 - acc: 0.7801 - val_loss: 0.6888 - val_acc: 0.7467\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 0.6246 - acc: 0.7870 - val_loss: 0.6805 - val_acc: 0.7647\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_train, y_input_train], y_train,\n",
    "            batch_size=32,\n",
    "            epochs=100,\n",
    "            validation_data=([x_val, y_input_val], y_val),\n",
    "            shuffle=\"batch\",\n",
    "            callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 78.70%; Val: 76.47%; Test: 76.87%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate([x_test, y_input_test], y_test, verbose=0)\n",
    "print(\"Train: %.2f%%; Val: %.2f%%; Test: %.2f%%\" % \n",
    "      (np.max(history.history['acc'])*100, np.max(history.history['val_acc'])*100, scores[1]*100)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"../output/saved/date_model_seq2seq_multiheads_80.20.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"../output/saved/date_weight_seq2seq_attention_80.20.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
