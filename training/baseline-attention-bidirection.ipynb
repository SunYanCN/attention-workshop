{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, SeparableConv2D\n",
    "from keras.layers import Bidirectional, RepeatVector, TimeDistributed, Permute\n",
    "from keras.layers import concatenate, add, Lambda, multiply\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.applications import imagenet_utils, Xception\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import TrainingMonitor\n",
    "from helpers import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xoh_file = open('../input/dataset/Xoh.pickle', 'rb')\n",
    "x = pickle.load(Xoh_file)\n",
    "Xoh_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yoh_file = open('../input/dataset/Yoh.pickle', 'rb')\n",
    "y = pickle.load(Yoh_file)\n",
    "Yoh_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 30, 37)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_split, val_split = 0.7, 0.15\n",
    "\n",
    "train_len = int(train_split * x.shape[0])\n",
    "train_val_len = int((train_split + val_split) * x.shape[0])\n",
    "\n",
    "x_train = x[:train_len]\n",
    "x_val = x[train_len:train_val_len]\n",
    "x_test = x[train_val_len:]\n",
    "\n",
    "y_train = y[:train_len]\n",
    "y_val = y[train_len:train_val_len]\n",
    "y_test = y[train_val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 30, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TIME_STEPS = x_train.shape[1]\n",
    "INPUT_DIM = x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention(inputs):\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    a_probs = Permute((2, 1))(a)\n",
    "    output_attention_mul = multiply([inputs, a_probs])\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 128)      52224       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 128, 30)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 30)      930         permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 30, 128)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 30, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3840)         0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 10, 3840)     0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 10, 128)      2032128     repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 10, 11)       1419        lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,086,701\n",
      "Trainable params: 2,086,701\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(30, 37,))\n",
    "bi_lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True))(inputs)\n",
    "attention_block = attention(bi_lstm)\n",
    "output = Flatten()(attention_block)\n",
    "output = RepeatVector(10)(output)\n",
    "output = LSTM(128, dropout=0.5, return_sequences=True)(output)\n",
    "output = TimeDistributed(Dense(11, activation=\"softmax\"))(output)\n",
    "model = Model(inputs, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9452\n"
     ]
    }
   ],
   "source": [
    "output_path = \"../output/\"\n",
    "\n",
    "print(os.getpid())\n",
    "filepath=output_path + \"progress/seq2seq-stacked-weights-best.hdf5\"\n",
    "MC = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "figPath = os.path.sep.join([output_path, \"monitor/{}.png\".format(os.getpid())])\n",
    "jsonPath = os.path.sep.join([output_path, \"monitor/{}.json\".format(os.getpid())])\n",
    "TM = TrainingMonitor(figPath, jsonPath=jsonPath, startAt=0)\n",
    "\n",
    "RLR = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [MC, TM, RLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 6s 8ms/step - loss: 2.2774 - acc: 0.1986 - val_loss: 2.1595 - val_acc: 0.2480\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 2.1202 - acc: 0.2413 - val_loss: 2.0593 - val_acc: 0.1660\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 2.0099 - acc: 0.2767 - val_loss: 1.9523 - val_acc: 0.3487\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.8989 - acc: 0.3707 - val_loss: 1.8205 - val_acc: 0.4047\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.7499 - acc: 0.4011 - val_loss: 1.6276 - val_acc: 0.4807\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.5039 - acc: 0.4813 - val_loss: 1.3210 - val_acc: 0.4873\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.2620 - acc: 0.4916 - val_loss: 1.2082 - val_acc: 0.4893\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.1937 - acc: 0.5121 - val_loss: 1.1614 - val_acc: 0.5347\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.1578 - acc: 0.5299 - val_loss: 1.1363 - val_acc: 0.5247\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.1358 - acc: 0.5381 - val_loss: 1.0903 - val_acc: 0.5593\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.1059 - acc: 0.5613 - val_loss: 1.0770 - val_acc: 0.5653\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.0906 - acc: 0.5649 - val_loss: 1.0532 - val_acc: 0.5753\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.0774 - acc: 0.5640 - val_loss: 1.0361 - val_acc: 0.5813\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.0545 - acc: 0.5800 - val_loss: 1.0000 - val_acc: 0.5933\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.0386 - acc: 0.5837 - val_loss: 1.0034 - val_acc: 0.5867\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.0449 - acc: 0.5827 - val_loss: 1.0254 - val_acc: 0.5740\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 1.0221 - acc: 0.5870 - val_loss: 0.9567 - val_acc: 0.6140\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9961 - acc: 0.6019 - val_loss: 0.9423 - val_acc: 0.6180\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9854 - acc: 0.6057 - val_loss: 0.9294 - val_acc: 0.6207\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9730 - acc: 0.6177 - val_loss: 0.9190 - val_acc: 0.6253\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9821 - acc: 0.6096 - val_loss: 0.9276 - val_acc: 0.6233\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9682 - acc: 0.6107 - val_loss: 0.9264 - val_acc: 0.6347\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9441 - acc: 0.6231 - val_loss: 0.8950 - val_acc: 0.6520\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9374 - acc: 0.6283 - val_loss: 0.8881 - val_acc: 0.6307\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9295 - acc: 0.6314 - val_loss: 0.8775 - val_acc: 0.6447\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9404 - acc: 0.6240 - val_loss: 0.8774 - val_acc: 0.6620\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9158 - acc: 0.6416 - val_loss: 0.8765 - val_acc: 0.6527\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9153 - acc: 0.6359 - val_loss: 0.8819 - val_acc: 0.6500\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.9097 - acc: 0.6376 - val_loss: 0.8570 - val_acc: 0.6593\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8989 - acc: 0.6424 - val_loss: 0.8557 - val_acc: 0.6680\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8883 - acc: 0.6501 - val_loss: 0.8430 - val_acc: 0.6693\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8803 - acc: 0.6540 - val_loss: 0.8405 - val_acc: 0.6800\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8841 - acc: 0.6476 - val_loss: 0.8421 - val_acc: 0.6627\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8724 - acc: 0.6561 - val_loss: 0.8317 - val_acc: 0.6667\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8706 - acc: 0.6554 - val_loss: 0.8230 - val_acc: 0.6707\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8499 - acc: 0.6654 - val_loss: 0.8157 - val_acc: 0.6807\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8490 - acc: 0.6694 - val_loss: 0.8140 - val_acc: 0.6820\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8376 - acc: 0.6764 - val_loss: 0.8014 - val_acc: 0.6773\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8282 - acc: 0.6811 - val_loss: 0.8000 - val_acc: 0.6773\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8185 - acc: 0.6851 - val_loss: 0.7943 - val_acc: 0.6907\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8401 - acc: 0.6709 - val_loss: 0.8031 - val_acc: 0.6800\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8200 - acc: 0.6824 - val_loss: 0.7859 - val_acc: 0.6880\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8158 - acc: 0.6854 - val_loss: 0.7946 - val_acc: 0.6767\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8153 - acc: 0.6853 - val_loss: 0.7979 - val_acc: 0.6800\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.8038 - acc: 0.6856 - val_loss: 0.7713 - val_acc: 0.6953\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7896 - acc: 0.6920 - val_loss: 0.7542 - val_acc: 0.7100\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7853 - acc: 0.6966 - val_loss: 0.7678 - val_acc: 0.7033\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7838 - acc: 0.7034 - val_loss: 0.7564 - val_acc: 0.7073\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7780 - acc: 0.7069 - val_loss: 0.7493 - val_acc: 0.7107\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7787 - acc: 0.7029 - val_loss: 0.7396 - val_acc: 0.7113\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7667 - acc: 0.7057 - val_loss: 0.7265 - val_acc: 0.7253\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7455 - acc: 0.7204 - val_loss: 0.7242 - val_acc: 0.7307\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7423 - acc: 0.7264 - val_loss: 0.7251 - val_acc: 0.7173\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7456 - acc: 0.7169 - val_loss: 0.7093 - val_acc: 0.7327\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7261 - acc: 0.7300 - val_loss: 0.6934 - val_acc: 0.7433\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7264 - acc: 0.7269 - val_loss: 0.6850 - val_acc: 0.7393\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7248 - acc: 0.7256 - val_loss: 0.6993 - val_acc: 0.7333\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7017 - acc: 0.7341 - val_loss: 0.6907 - val_acc: 0.7413\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7190 - acc: 0.7367 - val_loss: 0.6784 - val_acc: 0.7387\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7073 - acc: 0.7387 - val_loss: 0.6689 - val_acc: 0.7540\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6910 - acc: 0.7529 - val_loss: 0.6591 - val_acc: 0.7547\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6943 - acc: 0.7477 - val_loss: 0.6661 - val_acc: 0.7413\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6933 - acc: 0.7413 - val_loss: 0.6774 - val_acc: 0.7413\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.7229 - acc: 0.7339 - val_loss: 0.6622 - val_acc: 0.7680\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6861 - acc: 0.7503 - val_loss: 0.6761 - val_acc: 0.7567\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6758 - acc: 0.7509 - val_loss: 0.6429 - val_acc: 0.7640\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6659 - acc: 0.7614 - val_loss: 0.6416 - val_acc: 0.7667\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6567 - acc: 0.7597 - val_loss: 0.6279 - val_acc: 0.7687\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6540 - acc: 0.7626 - val_loss: 0.6255 - val_acc: 0.7787\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6552 - acc: 0.7606 - val_loss: 0.6192 - val_acc: 0.7633\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6480 - acc: 0.7646 - val_loss: 0.6194 - val_acc: 0.7787\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6291 - acc: 0.7721 - val_loss: 0.6226 - val_acc: 0.7733\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6428 - acc: 0.7646 - val_loss: 0.6235 - val_acc: 0.7693\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6380 - acc: 0.7686 - val_loss: 0.6192 - val_acc: 0.7713\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6330 - acc: 0.7724 - val_loss: 0.5991 - val_acc: 0.7953\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6141 - acc: 0.7784 - val_loss: 0.6031 - val_acc: 0.7767\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6151 - acc: 0.7787 - val_loss: 0.6076 - val_acc: 0.7747\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6017 - acc: 0.7860 - val_loss: 0.6018 - val_acc: 0.7860\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6044 - acc: 0.7787 - val_loss: 0.5966 - val_acc: 0.7867\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6062 - acc: 0.7867 - val_loss: 0.5903 - val_acc: 0.7853\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5936 - acc: 0.7826 - val_loss: 0.5932 - val_acc: 0.7820\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.6046 - acc: 0.7810 - val_loss: 0.5762 - val_acc: 0.7880\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5800 - acc: 0.7907 - val_loss: 0.5870 - val_acc: 0.7867\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5749 - acc: 0.7921 - val_loss: 0.5574 - val_acc: 0.8047\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5645 - acc: 0.7991 - val_loss: 0.5644 - val_acc: 0.8013\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5495 - acc: 0.8040 - val_loss: 0.5537 - val_acc: 0.8080\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5758 - acc: 0.7941 - val_loss: 0.5853 - val_acc: 0.7773\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5572 - acc: 0.7973 - val_loss: 0.5562 - val_acc: 0.8007\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5645 - acc: 0.7963 - val_loss: 0.5765 - val_acc: 0.7913\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5717 - acc: 0.7939 - val_loss: 0.5563 - val_acc: 0.7993\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5402 - acc: 0.8077 - val_loss: 0.5404 - val_acc: 0.8087\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5389 - acc: 0.8079 - val_loss: 0.5434 - val_acc: 0.8073\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5271 - acc: 0.8140 - val_loss: 0.5337 - val_acc: 0.8180\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5264 - acc: 0.8101 - val_loss: 0.5151 - val_acc: 0.8247\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5246 - acc: 0.8133 - val_loss: 0.5246 - val_acc: 0.8133\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5212 - acc: 0.8113 - val_loss: 0.5246 - val_acc: 0.8173\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5060 - acc: 0.8176 - val_loss: 0.5119 - val_acc: 0.8173\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5151 - acc: 0.8160 - val_loss: 0.5281 - val_acc: 0.8033\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.5013 - acc: 0.8191 - val_loss: 0.5079 - val_acc: 0.8200\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 3s 4ms/step - loss: 0.4927 - acc: 0.8284 - val_loss: 0.4941 - val_acc: 0.8240\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "            batch_size=32,\n",
    "            epochs=100,\n",
    "            validation_data=(x_val, y_val),\n",
    "            shuffle=\"batch\",\n",
    "            callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 82.84%; Val: 82.47%; Test: 83.13%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Train: %.2f%%; Val: %.2f%%; Test: %.2f%%\" % \n",
    "      (np.max(history.history['acc'])*100, np.max(history.history['val_acc'])*100, scores[1]*100)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"../output/saved/date_model_seq2seq_94.33.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"../output/saved/date_weight_seq2seq_94.33.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
