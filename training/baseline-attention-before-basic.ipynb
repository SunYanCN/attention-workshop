{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.applications import imagenet_utils, Xception\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import TrainingMonitor\n",
    "from helpers import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xoh_file = open('../input/dataset/Xoh.pickle', 'rb')\n",
    "x = pickle.load(Xoh_file)\n",
    "Xoh_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yoh_file = open('../input/dataset/Yoh.pickle', 'rb')\n",
    "y = pickle.load(Yoh_file)\n",
    "Yoh_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 37)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_split, val_split = 0.7, 0.15\n",
    "\n",
    "train_len = int(train_split * x.shape[0])\n",
    "train_val_len = int((train_split + val_split) * x.shape[0])\n",
    "\n",
    "x_train = x[:train_len]\n",
    "x_val = x[train_len:train_val_len]\n",
    "x_test = x[train_val_len:]\n",
    "\n",
    "y_train = y[:train_len]\n",
    "y_val = y[train_len:train_val_len]\n",
    "y_test = y[train_val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 30, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TIME_STEPS = x_train.shape[1]\n",
    "INPUT_DIM = x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention(inputs):\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    a_probs = Permute((2, 1))(a)\n",
    "    output_attention_mul = multiply([inputs, a_probs])\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
    "attention_mul = attention(inputs)\n",
    "output = LSTM(128)(attention_mul)\n",
    "output = RepeatVector(10)(output)\n",
    "output = LSTM(64, return_sequences=True)(output)\n",
    "output = TimeDistributed(Dense(11, activation=\"softmax\"))(output)\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 37, 30)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 37, 30)       930         permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 30, 37)       0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 30, 37)       0           input_2[0][0]                    \n",
      "                                                                 permute_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 128)          84992       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 10, 128)      0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 10, 64)       49408       repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 10, 11)       715         lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 136,045\n",
      "Trainable params: 136,045\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4908\n"
     ]
    }
   ],
   "source": [
    "output_path = \"../output/\"\n",
    "\n",
    "print(os.getpid())\n",
    "filepath=output_path + \"progress/seq2seq-attention-weights-best.hdf5\"\n",
    "MC = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "figPath = os.path.sep.join([output_path, \"monitor/{}.png\".format(os.getpid())])\n",
    "jsonPath = os.path.sep.join([output_path, \"monitor/{}.json\".format(os.getpid())])\n",
    "TM = TrainingMonitor(figPath, jsonPath=jsonPath, startAt=0)\n",
    "\n",
    "RLR = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [MC, TM, RLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 4s 5ms/step - loss: 2.2894 - acc: 0.1940 - val_loss: 2.1784 - val_acc: 0.2000\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 2.1430 - acc: 0.2369 - val_loss: 2.1156 - val_acc: 0.2520\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 2.0746 - acc: 0.2694 - val_loss: 2.0149 - val_acc: 0.1993\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.9794 - acc: 0.3111 - val_loss: 1.9261 - val_acc: 0.3033\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.8889 - acc: 0.3697 - val_loss: 1.8381 - val_acc: 0.4153\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.8114 - acc: 0.3873 - val_loss: 1.7689 - val_acc: 0.3813\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.7414 - acc: 0.3944 - val_loss: 1.7019 - val_acc: 0.3673\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.6674 - acc: 0.4120 - val_loss: 1.6038 - val_acc: 0.4800\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.5593 - acc: 0.4777 - val_loss: 1.4610 - val_acc: 0.4913\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.3834 - acc: 0.4859 - val_loss: 1.3027 - val_acc: 0.4940\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.2804 - acc: 0.4897 - val_loss: 1.2538 - val_acc: 0.4933\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.2458 - acc: 0.4941 - val_loss: 1.2440 - val_acc: 0.4907\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.2339 - acc: 0.4924 - val_loss: 1.2237 - val_acc: 0.4967\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.2168 - acc: 0.4933 - val_loss: 1.2180 - val_acc: 0.4920\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.2094 - acc: 0.4963 - val_loss: 1.2102 - val_acc: 0.4960\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.2035 - acc: 0.4906 - val_loss: 1.1943 - val_acc: 0.4953\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1953 - acc: 0.4930 - val_loss: 1.1865 - val_acc: 0.4993\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1917 - acc: 0.4926 - val_loss: 1.1877 - val_acc: 0.4967\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1891 - acc: 0.4967 - val_loss: 1.1863 - val_acc: 0.4980\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1853 - acc: 0.4953 - val_loss: 1.1812 - val_acc: 0.4953\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1833 - acc: 0.4959 - val_loss: 1.1802 - val_acc: 0.4980\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1819 - acc: 0.4939 - val_loss: 1.1780 - val_acc: 0.4920\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1802 - acc: 0.4939 - val_loss: 1.1762 - val_acc: 0.4960\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1764 - acc: 0.4931 - val_loss: 1.1722 - val_acc: 0.4993\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1731 - acc: 0.4966 - val_loss: 1.1770 - val_acc: 0.5027\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1746 - acc: 0.5037 - val_loss: 1.1697 - val_acc: 0.4953\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1723 - acc: 0.4970 - val_loss: 1.1747 - val_acc: 0.4853\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1721 - acc: 0.4954 - val_loss: 1.1715 - val_acc: 0.5033\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1726 - acc: 0.4956 - val_loss: 1.1733 - val_acc: 0.4960\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1702 - acc: 0.5011 - val_loss: 1.1707 - val_acc: 0.5000\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1687 - acc: 0.5000 - val_loss: 1.1697 - val_acc: 0.4993\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1703 - acc: 0.4997 - val_loss: 1.1736 - val_acc: 0.4880\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1659 - acc: 0.5033 - val_loss: 1.1665 - val_acc: 0.4933\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1647 - acc: 0.5031 - val_loss: 1.1675 - val_acc: 0.4933\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1643 - acc: 0.5019 - val_loss: 1.1664 - val_acc: 0.4927\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1639 - acc: 0.5047 - val_loss: 1.1671 - val_acc: 0.4967\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1639 - acc: 0.5010 - val_loss: 1.1665 - val_acc: 0.4933\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1637 - acc: 0.5010 - val_loss: 1.1665 - val_acc: 0.4953\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1633 - acc: 0.5020 - val_loss: 1.1663 - val_acc: 0.5007\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1639 - acc: 0.5047 - val_loss: 1.1661 - val_acc: 0.4973\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1633 - acc: 0.5016 - val_loss: 1.1660 - val_acc: 0.4920\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1632 - acc: 0.5019 - val_loss: 1.1657 - val_acc: 0.4973\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1630 - acc: 0.5023 - val_loss: 1.1657 - val_acc: 0.4933\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1630 - acc: 0.5020 - val_loss: 1.1667 - val_acc: 0.4967\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1634 - acc: 0.5020 - val_loss: 1.1654 - val_acc: 0.4940\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1629 - acc: 0.5009 - val_loss: 1.1653 - val_acc: 0.4947\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1629 - acc: 0.5030 - val_loss: 1.1657 - val_acc: 0.4927\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1623 - acc: 0.5029 - val_loss: 1.1653 - val_acc: 0.4920\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1621 - acc: 0.5020 - val_loss: 1.1647 - val_acc: 0.4933\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1627 - acc: 0.5026 - val_loss: 1.1654 - val_acc: 0.4953\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1627 - acc: 0.5001 - val_loss: 1.1637 - val_acc: 0.4953\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1626 - acc: 0.5026 - val_loss: 1.1654 - val_acc: 0.4940\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1625 - acc: 0.4980 - val_loss: 1.1645 - val_acc: 0.4973\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1621 - acc: 0.5027 - val_loss: 1.1637 - val_acc: 0.4960\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1622 - acc: 0.5046 - val_loss: 1.1642 - val_acc: 0.4940\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1617 - acc: 0.4961 - val_loss: 1.1647 - val_acc: 0.4927\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1613 - acc: 0.5029 - val_loss: 1.1647 - val_acc: 0.4940\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1606 - acc: 0.5050 - val_loss: 1.1639 - val_acc: 0.4947\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1604 - acc: 0.5043 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1604 - acc: 0.5040 - val_loss: 1.1643 - val_acc: 0.4920\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1603 - acc: 0.5053 - val_loss: 1.1637 - val_acc: 0.4940\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1605 - acc: 0.5020 - val_loss: 1.1642 - val_acc: 0.4933\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1599 - acc: 0.5053 - val_loss: 1.1641 - val_acc: 0.4933\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1599 - acc: 0.5049 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1599 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1599 - acc: 0.5054 - val_loss: 1.1640 - val_acc: 0.4933\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1599 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1598 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1598 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1598 - acc: 0.5053 - val_loss: 1.1641 - val_acc: 0.4940\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1598 - acc: 0.5053 - val_loss: 1.1641 - val_acc: 0.4940\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1598 - acc: 0.5053 - val_loss: 1.1641 - val_acc: 0.4940\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1641 - val_acc: 0.4940\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1641 - val_acc: 0.4940\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1641 - val_acc: 0.4940\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1641 - val_acc: 0.4940\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 1.1597 - acc: 0.5053 - val_loss: 1.1640 - val_acc: 0.4940\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "            batch_size=32,\n",
    "            epochs=100,\n",
    "            validation_data=(x_val, y_val),\n",
    "            shuffle=\"batch\",\n",
    "            callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 82.71%; Val: 80.27%; Test: 80.20%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Train: %.2f%%; Val: %.2f%%; Test: %.2f%%\" % \n",
    "      (np.max(history.history['acc'])*100, np.max(history.history['val_acc'])*100, scores[1]*100)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"../output/saved/date_model_seq2seq_attention_80.20.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"../output/saved/date_weight_seq2seq_attention_80.20.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
