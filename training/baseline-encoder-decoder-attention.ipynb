{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, SeparableConv2D\n",
    "from keras.layers import Bidirectional, RepeatVector, TimeDistributed, Permute, Embedding\n",
    "from keras.layers import concatenate, add, Lambda, multiply\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.applications import imagenet_utils, Xception\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import TrainingMonitor\n",
    "from helpers import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_file = open('../input/dataset/X.pickle', 'rb')\n",
    "x = pickle.load(X_file)\n",
    "X_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_file = open('../input/dataset/Y.pickle', 'rb')\n",
    "y = pickle.load(Y_file)\n",
    "Y_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_input = np.zeros([1000, 10])\n",
    "y_input[:, 1:] = y[:,:-1]\n",
    "y_input[:, 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.,   2.,  10.,  10.,   9.,   0.,   1.,   6.,   0.,   1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yoh_file = open('../input/dataset/Yoh.pickle', 'rb')\n",
    "yoh = pickle.load(Yoh_file)\n",
    "Yoh_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_split, val_split = 0.7, 0.15\n",
    "\n",
    "train_len = int(train_split * x.shape[0])\n",
    "train_val_len = int((train_split + val_split) * x.shape[0])\n",
    "\n",
    "x_train = x[:train_len]\n",
    "x_val = x[train_len:train_val_len]\n",
    "x_test = x[train_val_len:]\n",
    "\n",
    "y_input_train = y_input[:train_len]\n",
    "y_input_val = y_input[train_len:train_val_len]\n",
    "y_input_test = y_input[train_val_len:]\n",
    "\n",
    "yoh_train = yoh[:train_len]\n",
    "yoh_val = yoh[train_len:train_val_len]\n",
    "yoh_test = yoh[train_val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoh_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_LENGTH = 30\n",
    "OUTPUT_LENGTH = 10\n",
    "input_dict_size = 37\n",
    "output_dict_size = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
    "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder Tensor(\"lstm_1/transpose_2:0\", shape=(?, 30, 64), dtype=float32)\n",
      "decoder Tensor(\"lstm_2/transpose_2:0\", shape=(?, 10, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoder = Embedding(input_dict_size, 64, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
    "encoder = LSTM(64, return_sequences=True, unroll=True)(encoder)\n",
    "\n",
    "print('encoder', encoder)\n",
    "\n",
    "decoder = Embedding(output_dict_size, 64, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
    "decoder = LSTM(64, return_sequences=True, unroll=True)(decoder)\n",
    "\n",
    "print('decoder', decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, dot, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention Tensor(\"attention/truediv:0\", shape=(?, 10, 30), dtype=float32)\n",
      "context Tensor(\"dot_2/MatMul:0\", shape=(?, 10, 64), dtype=float32)\n",
      "decoder_combined_context Tensor(\"concatenate_1/concat:0\", shape=(?, 10, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attention = dot([decoder, encoder], axes=[2, 2])\n",
    "attention = Activation('softmax', name='attention')(attention)\n",
    "print('attention', attention)\n",
    "\n",
    "context = dot([attention, encoder], axes=[2,1])\n",
    "print('context', context)\n",
    "\n",
    "decoder_combined_context = concatenate([context, decoder])\n",
    "print('decoder_combined_context', decoder_combined_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_combined_context)\n",
    "output = TimeDistributed(Dense(11, activation=\"softmax\"))(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 10, 64)       704         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 64)       2368        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 10, 64)       33024       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 30, 64)       33024       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 10, 30)       0           lstm_2[0][0]                     \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, 10, 30)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 10, 64)       0           attention[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 128)      0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 10, 64)       8256        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 10, 11)       715         time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 78,091\n",
      "Trainable params: 78,091\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8280\n"
     ]
    }
   ],
   "source": [
    "output_path = \"../output/\"\n",
    "\n",
    "print(os.getpid())\n",
    "filepath=output_path + \"progress/seq2seq-attention-weights-best.hdf5\"\n",
    "MC = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "\n",
    "figPath = os.path.sep.join([output_path, \"monitor/{}.png\".format(os.getpid())])\n",
    "jsonPath = os.path.sep.join([output_path, \"monitor/{}.json\".format(os.getpid())])\n",
    "TM = TrainingMonitor(figPath, jsonPath=jsonPath, startAt=0)\n",
    "\n",
    "RLR = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [MC, TM, RLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 150 samples\n",
      "Epoch 1/50\n",
      "700/700 [==============================] - 8s 12ms/step - loss: 0.2938 - acc: 0.9090 - val_loss: 0.2817 - val_acc: 0.9091\n",
      "Epoch 2/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.2749 - acc: 0.9085 - val_loss: 0.2665 - val_acc: 0.9091\n",
      "Epoch 3/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.2547 - acc: 0.9120 - val_loss: 0.2404 - val_acc: 0.9130\n",
      "Epoch 4/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.2278 - acc: 0.9206 - val_loss: 0.2161 - val_acc: 0.9287\n",
      "Epoch 5/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.2030 - acc: 0.9369 - val_loss: 0.1925 - val_acc: 0.9420\n",
      "Epoch 6/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.1805 - acc: 0.9457 - val_loss: 0.1724 - val_acc: 0.9461\n",
      "Epoch 7/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.1631 - acc: 0.9482 - val_loss: 0.1593 - val_acc: 0.9473\n",
      "Epoch 8/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.1494 - acc: 0.9504 - val_loss: 0.1471 - val_acc: 0.9510\n",
      "Epoch 9/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.1394 - acc: 0.9528 - val_loss: 0.1361 - val_acc: 0.9542\n",
      "Epoch 10/50\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 0.1318 - acc: 0.9542 - val_loss: 0.1334 - val_acc: 0.9531\n",
      "Epoch 11/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.1269 - acc: 0.9552 - val_loss: 0.1267 - val_acc: 0.9557\n",
      "Epoch 12/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.1241 - acc: 0.9559 - val_loss: 0.1280 - val_acc: 0.9552\n",
      "Epoch 13/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.1201 - acc: 0.9567 - val_loss: 0.1194 - val_acc: 0.9580\n",
      "Epoch 14/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.1154 - acc: 0.9579 - val_loss: 0.1168 - val_acc: 0.9586\n",
      "Epoch 15/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.1126 - acc: 0.9586 - val_loss: 0.1130 - val_acc: 0.9593\n",
      "Epoch 16/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.1093 - acc: 0.9595 - val_loss: 0.1107 - val_acc: 0.9605\n",
      "Epoch 17/50\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 0.1050 - acc: 0.9610 - val_loss: 0.1064 - val_acc: 0.9610\n",
      "Epoch 18/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.1010 - acc: 0.9624 - val_loss: 0.1030 - val_acc: 0.9620\n",
      "Epoch 19/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0980 - acc: 0.9631 - val_loss: 0.1009 - val_acc: 0.9616\n",
      "Epoch 20/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0940 - acc: 0.9648 - val_loss: 0.0952 - val_acc: 0.9644\n",
      "Epoch 21/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0900 - acc: 0.9662 - val_loss: 0.0902 - val_acc: 0.9659\n",
      "Epoch 22/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0841 - acc: 0.9681 - val_loss: 0.0847 - val_acc: 0.9682\n",
      "Epoch 23/50\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 0.0792 - acc: 0.9699 - val_loss: 0.0802 - val_acc: 0.9702\n",
      "Epoch 24/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0751 - acc: 0.9716 - val_loss: 0.0760 - val_acc: 0.9727\n",
      "Epoch 25/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0706 - acc: 0.9731 - val_loss: 0.0709 - val_acc: 0.9733\n",
      "Epoch 26/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0657 - acc: 0.9754 - val_loss: 0.0701 - val_acc: 0.9742\n",
      "Epoch 27/50\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 0.0607 - acc: 0.9768 - val_loss: 0.0602 - val_acc: 0.9777\n",
      "Epoch 28/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0555 - acc: 0.9790 - val_loss: 0.0576 - val_acc: 0.9783\n",
      "Epoch 29/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0501 - acc: 0.9813 - val_loss: 0.0487 - val_acc: 0.9825\n",
      "Epoch 30/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0436 - acc: 0.9838 - val_loss: 0.0431 - val_acc: 0.9842\n",
      "Epoch 31/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0386 - acc: 0.9870 - val_loss: 0.0392 - val_acc: 0.9865\n",
      "Epoch 32/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0330 - acc: 0.9891 - val_loss: 0.0329 - val_acc: 0.9902\n",
      "Epoch 33/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0279 - acc: 0.9920 - val_loss: 0.0278 - val_acc: 0.9912\n",
      "Epoch 34/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0236 - acc: 0.9934 - val_loss: 0.0236 - val_acc: 0.9931\n",
      "Epoch 35/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0198 - acc: 0.9948 - val_loss: 0.0205 - val_acc: 0.9940\n",
      "Epoch 36/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0166 - acc: 0.9958 - val_loss: 0.0170 - val_acc: 0.9948\n",
      "Epoch 37/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0136 - acc: 0.9968 - val_loss: 0.0152 - val_acc: 0.9951\n",
      "Epoch 38/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0137 - val_acc: 0.9967\n",
      "Epoch 39/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0107 - acc: 0.9977 - val_loss: 0.0127 - val_acc: 0.9966\n",
      "Epoch 40/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0095 - acc: 0.9978 - val_loss: 0.0113 - val_acc: 0.9973\n",
      "Epoch 41/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0104 - val_acc: 0.9968\n",
      "Epoch 42/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0068 - acc: 0.9985 - val_loss: 0.0098 - val_acc: 0.9973\n",
      "Epoch 43/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.0099 - val_acc: 0.9978\n",
      "Epoch 44/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0082 - val_acc: 0.9983\n",
      "Epoch 45/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0049 - acc: 0.9989 - val_loss: 0.0082 - val_acc: 0.9973\n",
      "Epoch 46/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0040 - acc: 0.9995 - val_loss: 0.0076 - val_acc: 0.9983\n",
      "Epoch 47/50\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 0.0035 - acc: 0.9995 - val_loss: 0.0060 - val_acc: 0.9983\n",
      "Epoch 48/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9985\n",
      "Epoch 49/50\n",
      "700/700 [==============================] - 2s 2ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0064 - val_acc: 0.9986\n",
      "Epoch 50/50\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 0.0023 - acc: 0.9998 - val_loss: 0.0067 - val_acc: 0.9986\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[x_train, y_input_train], y=[yoh_train],\n",
    "            validation_data=([x_val, y_input_val], [yoh_val]),\n",
    "            verbose=1,\n",
    "            batch_size=32,\n",
    "            epochs=50,\n",
    "            shuffle=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 99.98%; Val: 99.86%; Test: 99.85%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate([x_test, y_input_test], yoh_test, verbose=0)\n",
    "print(\"Train: %.2f%%; Val: %.2f%%; Test: %.2f%%\" % \n",
    "      (np.max(history.history['acc'])*100, np.max(history.history['val_acc'])*100, scores[1]*100)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"../output/saved/date_model_attention_99.81.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"../output/saved/date_weight_attention_99.81.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attention_layer = model.get_layer(\"attention\")\n",
    "attention_model = Model(inputs=model.inputs, outputs=model.outputs + [attention_layer.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "human_vocab_file = open('../input/dataset/human_vocab.pickle', 'rb')\n",
    "human_vocab = pickle.load(human_vocab_file)\n",
    "human_vocab_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "machine_vocab_file = open('../input/dataset/machine_vocab.pickle', 'rb')\n",
    "machine_vocab = pickle.load(machine_vocab_file)\n",
    "machine_vocab_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_encoding = human_vocab\n",
    "output_encoding = machine_vocab\n",
    "input_decoding = {v: k for k, v in input_encoding.items()}\n",
    "output_decoding = {v: k for k, v in output_encoding.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input = x[0:1]\n",
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0, 24, 13, 34,  0,  4, 12, 12, 11, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.,   2.,  10.,  10.,   9.,   0.,   1.,   6.,   0.,   1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input = y_input[0:1]\n",
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_output= np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    output, attention = attention_model.predict([encoder_input, decoder_input])\n",
    "    decoder_output[:,i] = output.argmax(axis=2)[:,i]\n",
    "    attention_density = attention[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,  10.,  10.,   9.,   0.,   0.,   6.,   0.,   0.,  10.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 may 1998                    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ''\n",
    "for key, value in enumerate(encoder_input[0]):\n",
    "    if value != 36:\n",
    "        text += str(input_decoding[value])\n",
    "    else:\n",
    "        text += ' '\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1998--5--9'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = ''\n",
    "for key, value in enumerate(decoder_output[0]):\n",
    "    date += str(output_decoding[value])\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17931445ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAFpCAYAAAA7oFbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17931606ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "ax = seaborn.heatmap(attention_density[:len(date), : len(text)],\n",
    "        xticklabels=[w for w in text],\n",
    "        yticklabels=[w for w in date])\n",
    "\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
